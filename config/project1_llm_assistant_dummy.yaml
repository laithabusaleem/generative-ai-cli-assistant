model:
  # Offline mode: does NOT call any external API.
  # Uses DummyLLMClient which simply echoes your input.
  provider: dummy
  name: dummy-local
  temperature: 0.7
  max_tokens: 512

runtime:
  max_turns: 20

logging:
  level: info

